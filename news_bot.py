import os
import requests
import feedparser
import time
from datetime import datetime
from googletrans import Translator  # pip install googletrans==4.0.0-rc1

# ç¯å¢ƒå˜é‡
WEBHOOK_URL = os.getenv("FEISHU_WEBHOOK")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY")

# RSSæº
RSS_FEEDS = [
    "https://news.google.com/rss/search?q=southeast+asia+ecommerce+OR+cross-border+OR+logistics+OR+policy+OR+weather&hl=en&gl=SG&ceid=SG:en",
    "https://news.google.com/rss/search?q=philippines+ecommerce+OR+cross-border+OR+logistics+OR+policy+OR+weather&hl=en&gl=SG&ceid=SG:en",
    "https://news.google.com/rss/search?q=thailand+ecommerce+OR+cross-border+OR+logistics+OR+policy+OR+weather&hl=en&gl=SG&ceid=SG:en",
    "https://news.google.com/rss/search?q=malaysia+ecommerce+OR+cross-border+OR+logistics+OR+policy+OR+weather&hl=en&gl=SG&ceid=SG:en",
    "https://news.google.com/rss/search?q=vietnam+ecommerce+OR+cross-border+OR+logistics+OR+policy+OR+weather&hl=en&gl=SG&ceid=SG:en"
]

translator = Translator()

def get_latest_news():
    news_items = []
    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:2]:  # æ¯æºå–å‰2æ¡
                news_items.append({"title": entry.title, "link": entry.link})
        except Exception as e:
            print("RSSæŠ“å–å¤±è´¥:", e)
    return news_items

def summarize_with_gpt(news_title, retries=3, delay=2):
    """è°ƒç”¨ GPT ç”Ÿæˆæ‘˜è¦"""
    for attempt in range(retries):
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": "gpt-3.5-turbo",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸­æ–‡è·¨å¢ƒç”µå•†æ–°é—»ç¼–è¾‘ï¼Œå¸®æˆ‘ç”¨ç®€æ´ä¸­æ–‡æ€»ç»“æ–°é—»ï¼Œçªå‡ºå¯¹ä¸œå—äºšè·¨å¢ƒç”µå•†å½±å“ã€‚"},
                        {"role": "user", "content": f"æ–°é—»æ ‡é¢˜ï¼š{news_title}\nè¯·ç”¨ä¸­æ–‡å†™ä¸€å¥ç®€çŸ­æ‘˜è¦ï¼ˆ15å­—å†…ï¼‰"}
                    ],
                    "max_tokens": 60,
                },
                timeout=15
            )
            response.raise_for_status()
            data = response.json()
            summary = data["choices"][0]["message"]["content"].strip()
            if summary:
                return summary
        except Exception as e:
            print(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}, é‡è¯• {attempt+1}/{retries}")
        time.sleep(delay)

    # GPTå¤±è´¥æ—¶ç”¨Googleç¿»è¯‘æ ‡é¢˜
    try:
        translated = translator.translate(news_title, src='en', dest='zh-cn')
        return translated.text
    except Exception as e:
        print("ç¿»è¯‘å¤±è´¥:", e)
        return news_title  # æœ€åå…œåº•ç”¨åŸæ–‡

def shorten_link(url):
    """ç®€å•ç¼©çŸ­Google RSSé“¾æ¥"""
    if "articles/" in url:
        return "https://news.google.com/" + url.split("articles/")[1].split("?")[0]
    return url

def get_weather(city_name, country_code=""):
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”æƒ…å†µ"""
    if not OPENWEATHER_API_KEY:
        return "å¤©æ°”ä¿¡æ¯ä¸å¯ç”¨"
    try:
        q = f"{city_name},{country_code}" if country_code else city_name
        url = f"http://api.openweathermap.org/data/2.5/weather?q={q}&appid={OPENWEATHER_API_KEY}&units=metric&lang=zh_cn"
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        temp = data["main"]["temp"]
        desc = data["weather"][0]["description"]
        return f"{desc}, {temp}Â°C"
    except Exception as e:
        print(f"å¤©æ°”è·å–å¤±è´¥ ({city_name}):", e)
        return "å¤©æ°”ä¿¡æ¯ä¸å¯ç”¨"

def send_to_feishu(news_by_region):
    lines = []
    for region, items in news_by_region.items():
        # è·å–å¤©æ°”
        if region == "Thailand":
            weather = get_weather("Bangkok", "TH")
        elif region == "Malaysia":
            weather = get_weather("Kuala Lumpur", "MY")
        elif region == "Vietnam":
            weather = get_weather("Hanoi", "VN")
        elif region == "Philippines":
            weather = get_weather("Manila", "PH")
        else:
            weather = "å¤©æ°”ä¿¡æ¯ä¸å¯ç”¨"

        lines.append(f"ğŸŒ¤ {region} ä»Šæ—¥å¤©æ°”ï¼š{weather}\n")

        for news in items:
            short_link = shorten_link(news['link'])
            lines.append(f"ğŸ“° {news['title']}\nğŸ’¬ {news['summary']}\nğŸ”— {short_link}")

        lines.append("\n")  # å„åœ°åŒºåˆ†éš”

    text = "\n".join(lines) if lines else "ä»Šæ—¥æš‚æ— ç›¸å…³æ–°é—»"

    payload = {
        "msg_type": "text",
        "content": {"text": f"ğŸŒ ä»Šæ—¥ä¸œå—äºšè·¨å¢ƒç”µå•†å¿«è®¯ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M')}ï¼‰\n\n{text}"}
    }
    try:
        r = requests.post(WEBHOOK_URL, json=payload, timeout=10)
        r.raise_for_status()
        print("é£ä¹¦å‘é€æˆåŠŸ")
    except Exception as e:
        print("é£ä¹¦å‘é€å¤±è´¥:", e)

if __name__ == "__main__":
    news_data = get_latest_news()
    for item in news_data:
        item["summary"] = summarize_with_gpt(item["title"])

    # æŒ‰åœ°åŒºæ•´ç†
    news_by_region = {
        "Thailand": [],
        "Malaysia": [],
        "Vietnam": [],
        "Philippines": [],
        "Singapore": []
    }

    for item in news_data:
        title_lower = item["title"].lower()
        if "thailand" in title_lower:
            news_by_region["Thailand"].append(item)
        elif "malaysia" in title_lower:
            news_by_region["Malaysia"].append(item)
        elif "vietnam" in title_lower:
            news_by_region["Vietnam"].append(item)
        elif "philippines" in title_lower:
            news_by_region["Philippines"].append(item)
        else:
            news_by_region["Singapore"].append(item)

    send_to_feishu(news_by_region)
